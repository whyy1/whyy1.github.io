<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>歪衣的学习笔记</title>
    <link>https://whyy1.github.io/</link>
    <description>Recent content on 歪衣的学习笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 Feb 2023 19:52:42 +0800</lastBuildDate><atom:link href="https://whyy1.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>后端笔试总结</title>
      <link>https://whyy1.github.io/post/interview1/</link>
      <pubDate>Sun, 26 Feb 2023 19:52:42 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/interview1/</guid>
      <description>最近刚刚结束一个后端的笔试，里面有两道编程题，都不算很难。但是苦于答题语言只给了Java，而自己已经很久不写Java而且也不用Java刷题，所以只写了出了第一道。所以现在用Go重新来做一下这两道编程题
越是看起来简单的事情，越是要动手做起来
编程题1 给定两个数组，一个数组代表一个N进制数，数组的上每一位N进制数用10进制表示。例如
//16进制数6a7e表示为数组arra arra := []int{6, 10, 7,14} //16进制数3bcd表示为数组arrb arrb := []int{3, 11, 12,13} //他们的和为 result：=[]int{10, 6 ,4 ,11} 思路很简单，首先先将两个数组反转过来，然后对两个数组的每一位进行求和存进结果数组，如果这一位的和大于N就取余，然后在下一位加1。最后循环完两个数组后对结果再进行一次反转。
func addRadixArray(a, b []int, redix int) []int { result := make([]int, len(a)+1) revere(a) revere(b) for i := 0; i &amp;lt; len(a) || i &amp;lt; len(b); i++ { if i &amp;lt; len(a) { result[i] += a[i] } if i &amp;lt; len(b) { result[i] += b[i] } if result[i]/redix != 0 { result[i+1] = result[i] / redix result[i] %= redix } } //fmt.</description>
    </item>
    
    <item>
      <title>Redis小记</title>
      <link>https://whyy1.github.io/post/redis/</link>
      <pubDate>Wed, 22 Feb 2023 23:12:13 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/redis/</guid>
      <description>redis五种数据类型 String（字符串） 使用场景：常规的计数，用于缓存对象，共享session信息、做分布式锁，例如文章的点赞、播放量、转发，或者首页的热点数据
Hash（哈希） 和String一样是键值对存储，但是string只能存储一个数据，Hash可以存储一个对象，通常用string+json来达到同等效果。
使用场景：缓存对象。
List（列表） List 列表是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 列表添加元素。
使用场景：用来做消息队列(消息保序、处理重复的消息和保证消息的可靠性)
Set（集合） Set 类型是一个无序并唯一的键值集合，没有顺序，不能有重复值。
使用场景：共同关注、点赞、抽奖活动
Zset（有序集合） Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。保留了集合的不能有重复性，但是多了个排序。
使用场景：通常用于做排行榜功能因为Zset除了有一个有序的元素集合，还有另一个排序值，通过增大排序值来改变顺序。或者电话、姓名排序
缓存雪崩 通常都会选择把热点数据保存在redis中同时设置缓存过期时间并更新，当大量redis缓存同时失效或redis故障。这时候的请求就会都打到数据库上，这样很容易造成数据库宕机。
解决方法 均匀设置缓存的过期时间，不要其中在一起 设置互斥锁，当请求发现数据不在redis中需要去查询数据库时，加锁保证只有一个请求去建立缓存，暂时屏蔽其他请求，等到构建完毕才放开。（上锁设置超时时间，避免获取不到缓存等原因造成失锁） 双key策略：主key设置超时时间，从key设置不超时。当主key失效时，则去读从key，更新主key时同时更新从key 后台自动更新缓存：不断检测缓存是否有效，在缓存快过期时更新缓存。 redis故障，服务熔断或请求限流机制，出现故障时只允许一部分请求打入，其他全部拒绝 构建redis集群，主从redis，主redis宕机故障时使用从redis提供缓存服务 缓存击穿 也是redis失效，热点数据过期，此时大量请求访问热点数据，导致数据库访问量过大。和雪崩类似，但是是缓存雪崩的一个子集
缓存穿透 用户要访问的数据不在redis也不在数据库中，此时有大量请求访问，数据库压力突然增加，这就是缓存穿透。发生这种情况一个是业务误操作删除了数据，导致缓存和数据库中都没有数据，另一个就是黑客攻击，删除数据。
解决方法 1.对请求的参数进行校验，参数校验不过直接返回 2.增加缓存空值供这种情况查询，
缓存和数据库保持一致 先更新数据库再删除缓存，同时为了确保缓存删除成功，消息队列来重试缓存的删除或订阅 MySQL binlog 再操作缓存。(确保缓存删除成功的两种方案还不太了解，先记下)</description>
    </item>
    
    <item>
      <title>Http</title>
      <link>https://whyy1.github.io/post/http/</link>
      <pubDate>Tue, 21 Feb 2023 19:03:23 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/http/</guid>
      <description>TCP/IP四层网络模型 应用层（协议:HTTP(超文本传送协议),FTP(文件传送协议),Telnet(远程终端协议),DNS(域名系统),SMTP(简单邮件传送协议)） 服务于用户的层次，工作在操作系统中的用户态，应用层以下工作在内核态。
传输层 （协议:TCP,UDP） TCP(传输控制协议): 大部分应用使用的传输层协议，比如HTTP应用层协议。相比UDP它的特点就是能做到可靠传输，而依赖的就是流量控制、超时重传、拥塞控制、等机制，都是为了保证数据包能可靠传输数据包大小超过MSS(TCP 最大报文段长度为1460=1500-20(tcp头)-20(IP头))。
超时重传：TCP发送方发送报文后，需要接收方返回确认报文，只有接收到确认报文才会继续发送报文。不然的话超过计时器时间没有接收到确认报文，就会重新发送之前的报文。（需要对发送报文和确认报文进行编号） 确认丢失：当接收到重复的确认报文丢弃并继续发送 TCP报文首部字段：20字节
源端口和目的端口各2字节 序号:4字节，当前报文段第一个字节的序号，例如序号为301.长度为200字节 确认号:4字节，代表下一个报文段的第一个字节数序号，按照上面说法这个值为：501，即501之前的都收到了 确认ACK: 1bit，ACK为1时确认号字段才有效，建立连接后全都置为1 同步SYN: 1bit,置为1时为请求连接状态或接收连接状态，SYN为1、ACK为0时代表请求连接报文，连接成功后SYN、ACK都为1 终止FIN:1bit,为1时用于释放连接 窗口:2字节，0~2^16-1,用于表示发送此报文一方的接收窗口 数据偏移 保留 紧急URG:1bit,置为1代表紧急报文要尽快优先传送,1字节 推送PSH:1bit, 复位RST:1bit,为1代表TCP连接出现差错，需要重新创建连接 UDP(用户报数据报协议):只在IP数据报的基础上增加了很少一些功能，复用和分用，特点：尽最大的可能传输，不保证可靠交付、无连接的、UDP首部开销小(8字节:2源端口2目的端口2长度2检验和)、没有拥塞控制、
网络层(协议:IP) IP协议会将传输层的报文作为数据部分，再加上IP包头组装成IP报文，一般分片为一个MTU(1500字节)，
数据链路层 TCP三次握手 </description>
    </item>
    
    <item>
      <title>Go-micro框架使用踩坑笔记</title>
      <link>https://whyy1.github.io/post/go-micro/</link>
      <pubDate>Sat, 17 Dec 2022 21:20:07 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/go-micro/</guid>
      <description>真的，没想到平常买东西碰上了假货，没想到敲代码用框架也用上假的了。起初是安装micro框架，GitHub上搜出来的micro已经不支持go-micro的一些用法，但是它极为相似，第一次使用我也不太熟悉，弄了很久发现为啥micro框架生成的代码不大对劲，然后在网上找到一篇教程，才终于解答疑惑。go-micro安装
go-micro框架安装、使用 go-micro GitHub网址
首先在windows上安装go-micro go install github.com/go-micro/cli/cmd/go-micro@latest 或者 安装成功后输入go-micro -v查看是否安装成功
使用go-micro new命令初始化服务 使用命令go-micro new service helloworld 就会在当前路径下创建helloworl文件夹，其中包含一个service类型的微服务。
紧接着我们去修改proto文件，因为他初始化设置了很多参数，用来测试微服务是否能连接成功，所以我们只需要保留Call方法以及对应传入参数Request和传出参数Response。 定义好proto文件后，我们创建出对应的微服务go文件
//首先需要下载依赖 make //然后创建出按照proto文件生成的所需要的微服务go文件 make proto 我们只保留了Call方法，然后在Call方法中实现所需要的功能，用Request和Response来传输数据。
最后我们们修改main文件，增加consul作为服务发现 首先需要导入consul依赖,终端下运行
go get github.com/go-micro/plugins/v4/registry/consul
然后修改mian函数增加consul
//初始化consul配置 consulReg := consul.NewRegistry() // Create service srv := micro.NewService() srv.Init( micro.Name(service), micro.Version(version), micro.Registry(consulReg), //使用consul作为服务发现 micro.Address(&amp;#34;127.0.0.1:1111&amp;#34;), //增加consul服务指定的地址 ) `````` 这样一个微服务端就定义好了，接下来我们就可以在客户端中调用了。
在client调用微服务的Call函数 首先依然需要在client导入consul依赖,终端下运行
go get github.com/go-micro/plugins/v4/registry/consul
//初始化consul配置 consulReg := consul.NewRegistry() //创建一个microService,使用consul默认配置 consulService := micro.NewService( micro.Registry(consulReg), ) request := getCaptcha.CallRequest{} //创建micro客户端，第一个参数为服务名称，第二个参数为上面创建的consulService的Client microClient := getCaptcha.</description>
    </item>
    
    <item>
      <title>gRPC的定义以及简单使用(增加consul做为服务发现)</title>
      <link>https://whyy1.github.io/post/grpc/</link>
      <pubDate>Tue, 29 Nov 2022 22:31:42 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/grpc/</guid>
      <description>其实之前一直有了解微服务的概念，并且也写过一篇笔记记录相关概念，现在终于开始实操。最直观的认知就是，通过RPC框架的网络通信，可以实现不同语言之间的通信，通过protobuf来进行序列化message信息体，来实现通信。在客户端只需要注册微服务，然后远程调用就可以实现类似于本地函数的调用。
下面是gRPC基础调用例子实现：
首先需要定义proto文件，定义微服务以及消息体：
定义好如下文件，运行protoc --go_out=. --go-grpc_out=. .\hello.proto命令。就会在当前目录下生成*.pb.go文件,生成go文件，以便使用，尽量不要去修改这个文件。
//指定版本信息，默认为proto2 syntax = &amp;#34;proto3&amp;#34;; //后期生成go文件的包名，与输出文件在同一包下 package pb; //指定生成的两个*.pb.go文件输出到哪 //&amp;#34;/&amp;#34;为当前路径&amp;#34;/pb&amp;#34;则为pb文件夹下 option go_package = &amp;#34;/pb&amp;#34;; //定义消息体为Person message Person{ // 名字 string name = 1; // 年龄 int32 age = 2 ; } //定义RPC服务为HelloService service HelloService { //定义HelloService服务中的Hello函数 //入参和出参都是上方的Person，如果出参不同，需要另外定义message信息体 rpc Hello (Person)returns (Person); } 编写server端，注册gRPC服务提供服务
首先需要根据定义的微服务名称HelloServer定义结构体，并在其中加入Server变量,其次需要实现微服务中定义的Hello方法，如果有多个方法需要全部实现。 接下来就可以写Server的代码主体，server端注册服务的过程大同小异，一共需要做的有四步
使用grpc.NewServer()获取grpc服务端对象 用刚才生成pb包下的Register*Server函数注册gRPC服务 用net.Listen(&amp;ldquo;tcp&amp;rdquo;, Address)函数监听端口 最后使用grpcServer.Serve(lis)提供服务
这样就可以注册一个服务gRPC服务供其他程序调用了。 const ( Address = &amp;#34;:1234&amp;#34; ) //根据定义的服务名称实现结构体 type HelloServer struct { //必须定义一个指针类型参数 //此处HelloServer结构中包含一个未执行的HelloServiceServer *pb.</description>
    </item>
    
    <item>
      <title>利用协程实现的本地网络聊天室</title>
      <link>https://whyy1.github.io/post/channelroom/</link>
      <pubDate>Fri, 25 Nov 2022 19:14:48 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/channelroom/</guid>
      <description>通过原始的net包，在本地网络创建了一个聊天室，其中用到go routine并发编程、map加锁竞争使用、channel之间相互通信、切片的分割操作、定时器实现超时中断，知识点巩固很全面，下面总结一下
针对map中的读写，可以选择加读写锁，防止读写竞争问题。 对于切片的操作还不是很熟悉，但是通过切片的一些分割操作来实现字符串和和切片的转换。 并发执行go routine时channel尽量声明空间，无缓冲通过会发生堵塞。 通过将全局通道中的数据，赋值到每个用户中自己的通道，来实现全局发送。 使用select来监听协程，并创建一个bool型channel，通过监听channel的写入来达到一些自动化操作。 实现功能 在已登录用户中发送消息。 输入who查询已登录用户信息。 输入rename|[用户名]更改名字 用户上下线提醒
完整代码如下，因为是一个小东西，所以并没有分结构得很细，就全写在一个文件中了。 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net&amp;#34; &amp;#34;strings&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) type User struct { name string id string smg chan string } var ( //用map保存所有用户信息 allUsers = make(map[string]User) //定义全局信息通道 message = make(chan string, 10) //定义针对map的读写锁 rwLock sync.RWMutex ) func main() { listener, err := net.Listen(&amp;#34;tcp&amp;#34;, &amp;#34;:8080&amp;#34;) if err != nil { fmt.Println(&amp;#34;服务监听失败，错误为:&amp;#34;, err) } fmt.Println(&amp;#34;服务监听启动成功&amp;#34;) //启动全局广播go程 go broadcast() for { fmt.</description>
    </item>
    
    <item>
      <title>并发编程相关知识</title>
      <link>https://whyy1.github.io/post/go_revise1/</link>
      <pubDate>Thu, 24 Nov 2022 12:10:31 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/go_revise1/</guid>
      <description>进程 进程是程序在操作系统的一次执行过程，是操作系统进行资源分配的调度的一个最小单位(程序执行的最小单元)。是程序运行的载体。
线程 线程是进程执行中的一个实体，是CPU调度和分派的基本单位(操作系统分配的最小单元)，是比进程更小的能独立运行的基本单位。
进程和线程的比较 进程是程序执行的基本单元，而线程是操作系统分配资源的最小单元。 一个进程中包含一个或者多个线程，同一进程中的线程共享程序的内存空间并且可以并发执行。进程之间相互独立，进程中的线程对其他进程不可见。 线程比进程的上下文切换要快得多。 协程: 相比线程更加轻量，拥有独立的栈空间和栈内存，调度由用户自己控制，相当于轻量级的线程。类似于用户级别的线程，调度也是由用户实现。
协程和线程的比较 协程的栈空间比线程更小，线程默认是1M，而协程是1K，更加轻量级，因此在相同内存下可以开启更多的协程。 协程的切换在用户态，而线程的切换在内核态，因此减少了上下文消耗，提高了效率。 只有一个线程，不会出现锁竞争的情况造成阻塞，共享资源只需要判断状态就好了。但是不适用于需要大量计算的多线程，适用于被阻塞、需要大量并发的场景。 goroutine： golang中的并发设计的核心，也叫协程。它不需要用户关心底层逻辑内存分配、垃圾回收等，只需要专注于业务开发。每个4~5KB的栈空间内存占用，和由于实现机制而大幅减少的创造、销毁开销是Go高并发的核心。 Go语言的特点和优势 1．简单易学 2．自由高效 3．强大的标准库 4．部署方便 5．原生支持并发 6．稳定性强 7．垃圾回收
性能，go本身带有gc，虽然标榜与c系比肩，但在任何测评或实际使用中，go性能只能和java比一比，大概比非预热的java快10%左右，但是go的gc在大堆的处理上比java差很多，会导致比较高的延迟。go本身有很好的并发模型，写网络应用go要比java方便的多。 部署，云原生场景下go更适合，打包成二进制直接运行就行，也不特别依赖环境，比较方便；非云场景下java更适合，跨平台更方便。 生态，目前go主要在中间件和web后端、云原生应用发力，其他领域基本没什么建树；java因为发展这么久人也很多，基本上各个领域都有开花，web和安卓是霸主地位，桌面端你的IDEA、Goland都是java/kotlin开发的；大数据领域kafka、es、spark、flink都是java开发的；但是java在以k8s为基础的云原生领域就很薄弱，在非k8s有springcloud、dubbo支撑也很火；java各种轮子数不胜数基本上没有满足不了你需要的，go很多基础的东西要你自己写，很多三方库也不提供go的sdk，但是java是一定会有的，这点等你自己造轮子的时候就能体会到了。 并发 多线程程序在一个核的cpu上运行，就是并发。CPU根据时间片切分，交替执行多个程序。但是这个切换的过程我们用户是感知不到的。
并行 多线程程序在多个核的cpu上运行，就是并行。多核CPU在同时执行多个程序
并发和并行的区别： 并发主要由切换时间片来实现&amp;quot;同时&amp;quot;运行，并行则是直接利用多核实现多线程的运行，go可以设置使用核数，以发挥多核计算机的能力。
go语言中最小资源单位为go程&amp;mdash;-&amp;gt;goroutine,go语言原生支持并发，就是靠goroutine实现的。 只需要在函数前增加go关键字 在go中通过通信来共享内存，而不是通过共享内存来通信 通过创建计数器WaitGroup，来保证主程不会提前退出 //创建一个计数器WaitGroup， var wg sync.WaitGroup func main() { for i := 0; i &amp;lt; 10; i++ { wg.Add(1) //每启动一个go routine计数器+1 go hello(i) } fmt.Println(&amp;#34;主函数输出&amp;#34;) wg.Wait() //等待所有计数器为0时才退出 } func hello(i int) { defer wg.Done() //goroutine运行结束后计数器-1 fmt.</description>
    </item>
    
    <item>
      <title>MySQL小记</title>
      <link>https://whyy1.github.io/post/mysql_study/</link>
      <pubDate>Mon, 14 Nov 2022 23:50:17 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/mysql_study/</guid>
      <description>开启掘金成长之旅！这是我参与「掘金日新计划 · 2 月更文挑战」的第 2 天，点击查看活动详情
事务的ACID特性： 原子性(使用undo log回滚日志实现)： 事务要么全部执行，要么全部不执行，以原子单位进行处理。
一致性(使用持久性、一致性、原子性)： 事务执行的前后，数据的完整性保持一致。类似于银行转账，A向B转账，两个人总额是5000，转账完后总额还会是5000，中途不会不会有数据丢失。
隔离性(使用MVCC多版本控制或锁机制实现)： 一个事务的执行不会被其他事务所干扰。
持续性(使用redo log重做日志实现): 如果一个事务成功提交了，那么它造成的数据改变将是永久的，类似于数据持久化。
事务的隔离级别： 读未提交（防止丢失更新，造成脏读）： 一个事务可以读取到另一个事务已修改但未提交的数据修改，可以有效防止数据更新丢失。如果一个事务开始写数据，则另一个事务不允许同时进行写操作，但是可以读取数据。
脏读：事务A读取到事务B修改的数据，但是事务B却回滚了，读取到不存在的数据或错误数据。
读已提交（防止脏读，会造成不可重复读）： 事务在执行过程中，允许访问其他事务已经提交的插入或修改操作的数据。但是如果一个事务正在进行写事务且未提交，则禁止其他事务访问该行。可以有效防止脏读。
不可重复读：同一个事务中读取一行数据两次，得到两次不一样的结果。在第一次读取后，另一个事务更改了数据并成功提交，就会导致两次读取的数据不同。
可重复读（MySQL的默认事务隔离级别！！防止不可重复读，会造成幻读） 一个事务在执行过程中，可以访问其他事务提交的新插入的数据，但是不能访问其他事务成功修改的数据。读事务时会禁止其他写事务（允许读事务），写事务则禁止其他所有事务。可以有效防止不可重复读和脏读。
幻读：在一个事务中查询数据两次，第一次查询后其他事务提交了新插入的数据，就会造成第二次查询时多出了一条数据，这就是幻读。（和可重复读的区别时，一个是会读到两次不同的数据，一个是会读出多的一些数据）
可串行化（所以问题都可避免，但是造成锁竞争和超时现象） 提供严格的事务隔离，要求事务序列化执行，不能并发操作，即一个事务结束后才会运行下一个事务。可以解决事务并发时出现的问题，脏读、不可重复读、幻读等问题。但是这样会导致大量的超时现象和锁竞争，在实际应用中很少使用。 索引相关知识 什么是索引？ 索引是为了加速对表中数据行的检索而创建的一种分散的存储结构，用空间换时间。简单来说就是为了让存储引擎更快的查找获取数据。常见的索引有聚簇索引、主键索引、二级索引、唯一索引、hash索引、B+树索引。 Innodb的默认创建的主键索引为聚簇索引，是用B+树实现的，其他的属于二级索引或非聚簇索引。 B+Tree索引 数据都存储在叶子节点，非叶子节点存放键值+指针。 叶子节点中包含所有的索引。 每个小节点都在大节点的范围中。 叶子节点都是使用双指针链接，提高访问性能，比如条件是&amp;gt;或者＜。 如果B+树高度为2的话，根节点指针数*单个叶子节点记录行数 = 16kb/14 * 16 大约 1.8w+ 数据 如果B+树高度为3的话，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数 = 16kb/14 * 16kb/14 * 16 大约2kw+数据。 为什么使用B+树作为索引 一个是通过非叶子节点的结构，能够快速二分查找到数据，另一个是叶子节点通过双向链表连接，能够快速的进行区间范围查询。插入操作因为是通过主键自增的话，顺序插入很方便，并且删除时也只需要删除叶子节点就行。
Hash索引 Hash索引基于Hash表实现，只有查询条件精确匹配Hash索引中的所有列才会用到Hash索引。 存储引擎会为Hash索引中的每一列都计算Hash码，Hash索引中存储的即hash码，所以读取时会进行两次查询。 Hash索引无法用于排序。 Hash索引不使用于区分度小的列上，如性别字段。
B+树索引适合用来做范围查询，而HASH适合做等值查询、搜索复杂度为O（1） 二级索引 也是使用B+树存储，但是和聚簇索引不同的是，二级索引的叶子节点保存的是主键值。在使用二级索引列作为条件进行查询时，会先检索二级索引来获得主键值，然后再去查主键索引的B+树来获得数据，也就是回表。但是如果这时候需要获得的是主键值，就不需要再去查主键索引的B+树，而是直接获得主键值。
主键索引 建立在主键字段的索引，这一列必须是唯一的且不能为空
唯一索引 一列字段唯一的索引，但是可以为空
使用索引可能带来的问题 增加占用物理空间，数量越大，占用空间越大。 创建和维护索引都需要时间，当数据量越大时所花费的时间更多。 有可能让增删改变慢，因为每次进行增删改为了B+树的有序性，都需要维护索引。 适合使用索引的场景 字段唯一的，例如商品编码。 经常需要使用WHERE查询条件的字段，这样能够提高整个表的查询速度，如果查询条件是多个列时，使用联合索引。 经常用于GROUP BY和OREDER BY的字段，这样在查询的时候就不需要再次排序，因为基于B+树的有序性，建立索引之后的记录都是排序的。 MySQL的引擎 InnoDB引擎 假设有my_test 的database有个t_order表，则在/var/lib/mysql/my_test目录下有 t_order.</description>
    </item>
    
    <item>
      <title>Kubernetes</title>
      <link>https://whyy1.github.io/post/kubernetes/</link>
      <pubDate>Thu, 10 Nov 2022 22:46:20 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/kubernetes/</guid>
      <description>最近把自己一个小玩意儿用docker部署到服务器后，开始尝试了解kubernetes，但是看了一眼阿里云k8s的收费情况，作为学生党当然是选择白嫖。现阶段只是了解学习的阶段，所以选择使用minikube来学习了解k8s。参考文档
Kubernetes 集群 Kubernetes 协调一个高可用计算机集群，每个计算机作为独立单元互相连接工作。 一个 Kubernetes 集群包含两种类型的资源:
Master 调度整个集群
Master节点负责管理整个集群，控制工作节点。 Nodes 负责运行应用
Node是一个虚拟机或者物理机，作为一个工作节点。它在 Kubernetes 集群中充当工作机器的角色，应该具有Kubelet：管理 Node 而且是 Node 与 Master 通信的代理以及用于处理容器操作的工具。
Master 管理集群，Node 用于托管正在运行的应用。 Deployment （部署） 创建 Kubernetes Deployment 配置，Deployment 指挥 Kubernetes 如何创建和更新应用程序的实例。通过修改Deployment文件来控制kubernetes来创建或是修改Pod。个人理解类似于dockerfile，表示应该如何创建Pods。
相关命令
# 查看 deployment kubectl get deployment # 创建命令，可以指定镜像版本 kubectl create deployment hello-node --image=registry.k8s.io/echoserver:1.4 # 也可以通过pod.yaml来部署Pod kubectl apply -f .\pod.yaml # 删除deployment kubectl delete deployment hello-minikube Pods kubernetes调度、管理的最小单位，一个Pod里面可以包含一个或多个容器，每个 Pod 有自己的虚拟IP。是运行一个应用程序的最小单元。
相关命令
# 查看Pods kubectl get pods # 通过命令行运行 kubectl run testapp --image=ccr.</description>
    </item>
    
    <item>
      <title>Hugo博客部署流程</title>
      <link>https://whyy1.github.io/post/hugo_add/</link>
      <pubDate>Tue, 08 Nov 2022 23:33:06 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/hugo_add/</guid>
      <description>Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。参考了文档以及一个UP主的视频，花了一个晚上的时间弄了一个人博客，最直观的感觉就是非常快速方便。博客地址
下面来做一下总结和流程回顾，首先需要安装Git和Hugo,可以参考视频和文档，都挺详细的。如何验证是否安装成功，运行以下命令出现版本号就说明安装成功了。
hugo version git version 安装好后就可以开始搭建自己的个人博客啦，此文主要记录一些常用操作。Hugo中文网站 、参考视频。
1.创建一个Hugo站点 进入你想要保存文件夹的路径，然后进入CMD，输入以下代码
hugo new site y1_blog #最后为文件夹名字 之后在路径下就会创建一个名为y1_blog的文件夹
2.选取一款皮肤主题 之后进入y1_blog文件夹，选取一款主题安装。皮肤主题网站Hugo上有挺多主题提供选择，我选择的主题是Paper，进入到y1_blog后，运行
git submodule add https://github.com/nanxiaobei/hugo-paper themes/paper 然后在y1_blog\themes下就会多了个paper文件夹，说明已经下载好了，然后在y1_blog目录下修改 config.toml文件的theme为paper
theme = &amp;#34;paper&amp;#34; 同时还可以设置其他一些信息
title = &amp;#39;歪衣的学习笔记&amp;#39; #博客标题名 github = &amp;#39;whyy1&amp;#39; #github用户名 avatar = &amp;#39;https://cdn.whyy1.top/avatar.svg&amp;#39; #设置头像照片链接，格式为svg name = &amp;#39;歪衣&amp;#39; #设置博客用户名字 bio = &amp;#39;学习是稳赚不赔的投资&amp;#39; #设置个性签名 3.启动Hugo服务器 设置好之后，在y1_blog根目录下运行以下命令，就能启动Hugo服务器了。
hugo server -D 如图最后所示，网址输入http://localhost:1313/ 就能访问了。 4.添加一篇文章 刚新建时因为没有文章，所以头像名字啥的有可能显示不出来，因此我们需要新建一篇文章，使用到的命令如下，在y1_blog\content\post\目录下就会新建一个essay.md文件，这是用Markdown格式写的一篇文章。Markdown教程
hugo new post/essay.md 添加好之后再次运行hugo server -D启动Hugo服务器，就可以看到刚才写的文章啦。
5.将博客部署到GitHub上 首先在GitHub上新建一个repository
新建好后复制repository的地址，例如https://whyy1.github.io/ ，然后之后进行一系列上传Git的操作，直接上代码块，有注释，也可以参考视频13:40~20:00的内容。
#在y1_blog/目录下CMD运行 #theme为主题，baseUrl为刚才新建的仓库地址 --buildDrafts为y1_blog/public/目录下生成静态文件 hugo --theme=paper --baseUrl=&amp;#34;https://whyy1.</description>
    </item>
    
    <item>
      <title>docker常用命令</title>
      <link>https://whyy1.github.io/post/essay/</link>
      <pubDate>Tue, 01 Nov 2022 22:48:44 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/essay/</guid>
      <description>Docker镜像创建 创建dockerflie文件 # 最低版本go的依赖 FROM golang:1.17.7 # 配置模块代理 ENV GOPROXY=https://goproxy.cn,direct # 复制文件目录下的所有代码 ADD . /whygo #默认进入文件目录 WORKDIR /whygo # 复制代码 ADD /whygo/go.mod . ADD /whygo/go.sum . # 下载依赖 RUN go mod download # 运行命令，安装依赖 # 例如 RUN npm install &amp;amp;&amp;amp; cd /app &amp;amp;&amp;amp; mkdir logs # ADD ./whygo . ENV CGO_ENABLED=0 ENV GOOS=linux ENV GOARCH=amd64 # RUN 命令可以有多个，但是可以用 &amp;amp;&amp;amp; 连接多个命令来减少层级。 # 构建exe文件，名字为demo RUN go build -tags netgo -o demo # CMD 指令只能一个，是容器启动后执行的命令，算是程序的入口。 # 默认运行 demo ENTRYPOINT [ &amp;#34;.</description>
    </item>
    
  </channel>
</rss>
