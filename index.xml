<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>歪衣的学习笔记</title>
    <link>https://whyy1.github.io/</link>
    <description>Recent content on 歪衣的学习笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Feb 2023 23:12:13 +0800</lastBuildDate><atom:link href="https://whyy1.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Redis小记</title>
      <link>https://whyy1.github.io/post/redis/</link>
      <pubDate>Wed, 22 Feb 2023 23:12:13 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/redis/</guid>
      <description>redis五种数据类型 String（字符串） 使用场景：热点数据的缓存，例如文章的点赞、播放量、转发，或者首页的热点数据 Hash（哈希） 和String一样是键值对存储，但是string只能存储一个数据，Hash可以存储一个对象，通常用string+json来达到同等效果。 List（列表） List 列表是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 列表添加元素。 Set（集合） Set 类型是一个无序并唯一的键值集合 Zset（有序集合） Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。
通常用于做排行榜功能，因为Zset除了有一个有序的元素集合，还有另一个排序值，通过增大排序值来改变驯熟 缓存雪崩 通常都会选择把热点数据保存在redis中同时设置缓存过期时间并更新，当大量redis缓存同时失效或redis故障。这时候的请求就会都打到数据库上，这样很容易造成数据库宕机。
解决方法 均匀设置缓存的过期时间，不要其中在一起 设置互斥锁，当请求发现数据不在redis中需要去查询数据库时，加锁保证只有一个请求去建立缓存，暂时屏蔽其他请求，等到构建完毕才放开。（上锁设置超时时间，避免获取不到缓存等原因造成失锁） 双key策略：主key设置超时时间，从key设置不超时。当主key失效时，则去读从key，更新主key时同时更新从key 后台自动更新缓存：不断检测缓存是否有效，在缓存快过期时更新缓存。 redis故障，服务熔断或请求限流机制，出现故障时只允许一部分请求打入，其他全部拒绝 构建redis集群，主从redis，主redis宕机故障时使用从redis提供缓存服务 缓存击穿 也是redis失效，热点数据过期，此时大量请求访问热点数据，导致数据库访问量过大。和雪崩类似，但是是缓存雪崩的一个子集
缓存穿透 用户要访问的数据不在redis也不在数据库中，此时有大量请求访问，数据库压力突然增加，这就是缓存穿透。发生这种情况一个是业务误操作删除了数据，导致缓存和数据库中都没有数据，另一个就是黑客攻击，删除数据。
解决方法 1.对请求的参数进行校验，参数校验不过直接返回 2.增加缓存空值供这种情况查询，
缓存和数据库保持一致 先更新数据库再删除缓存，同时为了确保缓存删除成功，消息队列来重试缓存的删除或订阅 MySQL binlog 再操作缓存。(确保缓存删除成功的两种方案还不太了解，先记下)</description>
    </item>
    
    <item>
      <title>Http</title>
      <link>https://whyy1.github.io/post/http/</link>
      <pubDate>Tue, 21 Feb 2023 19:03:23 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/http/</guid>
      <description>TCP/IP四层网络模型 应用层（协议:HTTP(超文本传送协议),FTP(文件传送协议),Telnet(远程终端协议),DNS(域名系统),SMTP(简单邮件传送协议)） 服务于用户的层次，工作在操作系统中的用户态，应用层以下工作在内核态。
传输层 （协议:TCP,UDP） TCP(传输控制协议): 大部分应用使用的传输层协议，比如HTTP应用层协议。相比UDP它的特点就是能做到可靠传输，而依赖的就是流量控制、超时重传、拥塞控制、等机制，都是为了保证数据包能可靠传输数据包大小超过MSS(TCP 最大报文段长度为1460=1500-20(tcp头)-20(IP头))。
超时重传：TCP发送方发送报文后，需要接收方返回确认报文，只有接收到确认报文才会继续发送报文。不然的话超过计时器时间没有接收到确认报文，就会重新发送之前的报文。（需要对发送报文和确认报文进行编号） 确认丢失：当接收到重复的确认报文丢弃并继续发送 TCP报文首部字段：20字节
源端口和目的端口各2字节 序号:4字节，当前报文段第一个字节的序号，例如序号为301.长度为200字节 确认号:4字节，代表下一个报文段的第一个字节数序号，按照上面说法这个值为：501，即501之前的都收到了 确认ACK: 1bit，ACK为1时确认号字段才有效，建立连接后全都置为1 同步SYN: 1bit,置为1时为请求连接状态或接收连接状态，SYN为1、ACK为0时代表请求连接报文，连接成功后SYN、ACK都为1 终止FIN:1bit,为1时用于释放连接 窗口:2字节，0~2^16-1,用于表示发送此报文一方的接收窗口 数据偏移 保留 紧急URG:1bit,置为1代表紧急报文要尽快优先传送,1字节 推送PSH:1bit, 复位RST:1bit,为1代表TCP连接出现差错，需要重新创建连接 UDP(用户报数据报协议):只在IP数据报的基础上增加了很少一些功能，复用和分用，特点：尽最大的可能传输，不保证可靠交付、无连接的、UDP首部开销小(8字节:2源端口2目的端口2长度2检验和)、没有拥塞控制、
网络层(协议:IP) IP协议会将传输层的报文作为数据部分，再加上IP包头组装成IP报文，一般分片为一个MTU(1500字节)，
数据链路层 TCP三次握手 </description>
    </item>
    
    <item>
      <title>Go-micro框架使用踩坑笔记</title>
      <link>https://whyy1.github.io/post/go-micro/</link>
      <pubDate>Sat, 17 Dec 2022 21:20:07 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/go-micro/</guid>
      <description>真的，没想到平常买东西碰上了假货，没想到敲代码用框架也用上假的了。起初是安装micro框架，GitHub上搜出来的micro已经不支持go-micro的一些用法，但是它极为相似，第一次使用我也不太熟悉，弄了很久发现为啥micro框架生成的代码不大对劲，然后在网上找到一篇教程，才终于解答疑惑。go-micro安装
go-micro框架安装、使用 go-micro GitHub网址
首先在windows上安装go-micro go install github.com/go-micro/cli/cmd/go-micro@latest 或者 安装成功后输入go-micro -v查看是否安装成功
使用go-micro new命令初始化服务 使用命令go-micro new service helloworld 就会在当前路径下创建helloworl文件夹，其中包含一个service类型的微服务。
紧接着我们去修改proto文件，因为他初始化设置了很多参数，用来测试微服务是否能连接成功，所以我们只需要保留Call方法以及对应传入参数Request和传出参数Response。 定义好proto文件后，我们创建出对应的微服务go文件
//首先需要下载依赖 make //然后创建出按照proto文件生成的所需要的微服务go文件 make proto 我们只保留了Call方法，然后在Call方法中实现所需要的功能，用Request和Response来传输数据。
最后我们们修改main文件，增加consul作为服务发现 首先需要导入consul依赖,终端下运行
go get github.com/go-micro/plugins/v4/registry/consul
然后修改mian函数增加consul
//初始化consul配置 consulReg := consul.NewRegistry() // Create service srv := micro.NewService() srv.Init( micro.Name(service), micro.Version(version), micro.Registry(consulReg), //使用consul作为服务发现 micro.Address(&amp;#34;127.0.0.1:1111&amp;#34;), //增加consul服务指定的地址 ) `````` 这样一个微服务端就定义好了，接下来我们就可以在客户端中调用了。
在client调用微服务的Call函数 首先依然需要在client导入consul依赖,终端下运行
go get github.com/go-micro/plugins/v4/registry/consul
//初始化consul配置 consulReg := consul.NewRegistry() //创建一个microService,使用consul默认配置 consulService := micro.NewService( micro.Registry(consulReg), ) request := getCaptcha.CallRequest{} //创建micro客户端，第一个参数为服务名称，第二个参数为上面创建的consulService的Client microClient := getCaptcha.</description>
    </item>
    
    <item>
      <title>gRPC的定义以及简单使用(增加consul做为服务发现)</title>
      <link>https://whyy1.github.io/post/grpc/</link>
      <pubDate>Tue, 29 Nov 2022 22:31:42 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/grpc/</guid>
      <description>其实之前一直有了解微服务的概念，并且也写过一篇笔记记录相关概念，现在终于开始实操。最直观的认知就是，通过RPC框架的网络通信，可以实现不同语言之间的通信，通过protobuf来进行序列化message信息体，来实现通信。在客户端只需要注册微服务，然后远程调用就可以实现类似于本地函数的调用。
下面是gRPC基础调用例子实现：
首先需要定义proto文件，定义微服务以及消息体：
定义好如下文件，运行protoc --go_out=. --go-grpc_out=. .\hello.proto命令。就会在当前目录下生成*.pb.go文件,生成go文件，以便使用，尽量不要去修改这个文件。
//指定版本信息，默认为proto2 syntax = &amp;#34;proto3&amp;#34;; //后期生成go文件的包名，与输出文件在同一包下 package pb; //指定生成的两个*.pb.go文件输出到哪 //&amp;#34;/&amp;#34;为当前路径&amp;#34;/pb&amp;#34;则为pb文件夹下 option go_package = &amp;#34;/pb&amp;#34;; //定义消息体为Person message Person{ // 名字 string name = 1; // 年龄 int32 age = 2 ; } //定义RPC服务为HelloService service HelloService { //定义HelloService服务中的Hello函数 //入参和出参都是上方的Person，如果出参不同，需要另外定义message信息体 rpc Hello (Person)returns (Person); } 编写server端，注册gRPC服务提供服务
首先需要根据定义的微服务名称HelloServer定义结构体，并在其中加入Server变量,其次需要实现微服务中定义的Hello方法，如果有多个方法需要全部实现。 接下来就可以写Server的代码主体，server端注册服务的过程大同小异，一共需要做的有四步
使用grpc.NewServer()获取grpc服务端对象 用刚才生成pb包下的Register*Server函数注册gRPC服务 用net.Listen(&amp;ldquo;tcp&amp;rdquo;, Address)函数监听端口 最后使用grpcServer.Serve(lis)提供服务
这样就可以注册一个服务gRPC服务供其他程序调用了。 const ( Address = &amp;#34;:1234&amp;#34; ) //根据定义的服务名称实现结构体 type HelloServer struct { //必须定义一个指针类型参数 //此处HelloServer结构中包含一个未执行的HelloServiceServer *pb.</description>
    </item>
    
    <item>
      <title>利用协程实现的本地网络聊天室</title>
      <link>https://whyy1.github.io/post/channelroom/</link>
      <pubDate>Fri, 25 Nov 2022 19:14:48 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/channelroom/</guid>
      <description>通过原始的net包，在本地网络创建了一个聊天室，其中用到go routine并发编程、map加锁竞争使用、channel之间相互通信、切片的分割操作、定时器实现超时中断，知识点巩固很全面，下面总结一下
针对map中的读写，可以选择加读写锁，防止读写竞争问题。 对于切片的操作还不是很熟悉，但是通过切片的一些分割操作来实现字符串和和切片的转换。 并发执行go routine时channel尽量声明空间，无缓冲通过会发生堵塞。 通过将全局通道中的数据，赋值到每个用户中自己的通道，来实现全局发送。 使用select来监听协程，并创建一个bool型channel，通过监听channel的写入来达到一些自动化操作。 实现功能 在已登录用户中发送消息。 输入who查询已登录用户信息。 输入rename|[用户名]更改名字 用户上下线提醒
完整代码如下，因为是一个小东西，所以并没有分结构得很细，就全写在一个文件中了。 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;net&amp;#34; &amp;#34;strings&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) type User struct { name string id string smg chan string } var ( //用map保存所有用户信息 allUsers = make(map[string]User) //定义全局信息通道 message = make(chan string, 10) //定义针对map的读写锁 rwLock sync.RWMutex ) func main() { listener, err := net.Listen(&amp;#34;tcp&amp;#34;, &amp;#34;:8080&amp;#34;) if err != nil { fmt.Println(&amp;#34;服务监听失败，错误为:&amp;#34;, err) } fmt.Println(&amp;#34;服务监听启动成功&amp;#34;) //启动全局广播go程 go broadcast() for { fmt.</description>
    </item>
    
    <item>
      <title>并发编程相关知识</title>
      <link>https://whyy1.github.io/post/go_revise1/</link>
      <pubDate>Thu, 24 Nov 2022 12:10:31 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/go_revise1/</guid>
      <description>进程：进程是程序在操作系统的一次执行过程，是进行资源分配的调度的一个最小单位。（一个进程可以创建和撤销多个线程；在同一进程中线程可以并发执行）
线程：线程是进程执行中的一个实体，是CPU调度和分派的基本单位，是比进程更小的能独立运行的基本单位。
并发：多线程程序在一个核的cpu上运行，就是并发。CPU根据时间片切分，交替执行多个程序。但是这个切换的过程我们用户是感知不到的。
并行：多线程程序在多个核的cpu上运行，就是并行。多核CPU在同时执行多个程序
并发和并行的区别： 并发主要由切换时间片来实现&amp;quot;同时&amp;quot;运行，并行则是直接利用多核实现多线程的运行，go可以设置使用核数，以发挥多核计算机的能力。
go语言中最小资源单位为go程&amp;mdash;-&amp;gt;goroutine,go语言原生支持并发，就是靠goroutine实现的。 只需要在函数前增加go关键字 在go中通过通信来共享内存，而不是通过共享内存来通信 通过创建计数器WaitGroup，来保证主程不会提前退出 //创建一个计数器WaitGroup， var wg sync.WaitGroup func main() { for i := 0; i &amp;lt; 10; i++ { wg.Add(1) //每启动一个go routine计数器+1 go hello(i) } fmt.Println(&amp;#34;主函数输出&amp;#34;) wg.Wait() //等待所有计数器为0时才退出 } func hello(i int) { defer wg.Done() //goroutine运行结束后计数器-1 fmt.Println(&amp;#34;运行go程:&amp;#34;, i) } 管道之间通信：
通常通过for range来遍历管道内的数据，并且以此来判断有没有关闭 双向通道可以赋值给单向读、写通道，但是反过来不行 通道写完后一定要关闭，同时要保证读写次数一致， var wg1 sync.WaitGroup func main() { //声明channel变量如果不用make初始化则为nil var ch1 chan int // 声明一个传递整型的通道 fmt.Println(ch1) //此时为空，因为没有初始化 //创建无缓冲管道 //numChan := make(chan int) //创建有缓冲管道 numChan := make(chan int, 10) wg1.</description>
    </item>
    
    <item>
      <title>MySQL小记</title>
      <link>https://whyy1.github.io/post/mysql_study/</link>
      <pubDate>Mon, 14 Nov 2022 23:50:17 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/mysql_study/</guid>
      <description>事务的ACID特性： 原子性： 事务要么全部执行，要么全部不执行，以原子单位进行处理。
一致性： 事务执行的前后，数据的完整性保持一致。类似于银行转账，A向B转账，两个人总额是5000，转账完后总额还会是5000，中途不会不会有数据丢失。
隔离性： 一个事务的执行不会被其他事务所干扰。
持续性 如果一个事务成功提交了，那么它造成的数据改变将是永久的，类似于数据持久化。
事务的隔离级别： 读未提交（防止丢失更新，造成脏读）： 一个事务可以读取到另一个事务已修改但未提交的数据修改，可以有效防止数据更新丢失。如果一个事务开始写数据，则另一个事务不允许同时进行写操作，但是可以读取数据。
脏读：事务A读取到事务B修改的数据，但是事务B却回滚了，读取到不存在的数据或错误数据。
读已提交（防止脏读，会造成不可重复读）： 事务在执行过程中，允许访问其他事务已经提交的插入或修改操作的数据。但是如果一个事务正在进行写事务且未提交，则禁止其他事务访问该行。可以有效防止脏读。
不可重复读：同一个事务中读取 一行数据两次，得到两次不一样的结果。在第一次读取后，另一个事务更改了数据并成功提交，就会导致两次读取的数据不同。
可重复读（MySQL的默认事务隔离级别！！防止不可重复读，会造成幻读） 一个事务在执行过程中，可以访问其他事务提交的新插入的数据，但是不能访问其他事务成功修改的数据。读事务时会禁止其他写事务（允许读事务），写事务则禁止其他所有事务。可以有效防止不可重复读和脏读。
幻读：在一个事务中查询数据两次，第一次查询后其他事务提交了新插入的数据，就会造成第二次查询时多出了一条数据，这就是幻读。（和可重复读的区别时，一个是会读到两次不同的数据，一个是会读出多的一些数据）
可串行化（所以问题都可避免，但是造成锁竞争和超时现象） 提供严格的事务隔离，要求事务序列化执行，不能并发操作，即一个事务结束后才会运行下一个事务。可以解决事务并发时出现的问题，脏读、不可重复读、幻读等问题。但是这样会导致大量的超时现象和锁竞争，在实际应用中很少使用。 MySQL的引擎 InnoDB引擎 假设有my_test 的database有个t_order表，则在/var/lib/mysql/my_test目录下有 t_order.ibd，t_order 的表数据保存在这个文件
t_order.frm ，t_order 的表结构会保存在这个文件
表空间结构 表空间由段&amp;gt;区&amp;gt;页&amp;gt;行的包含关系存储，InnoDB 的数据是按页为单位来读写的，每页的大小为16KB MySQL的默认引擎，提供了事务操作并使用了可重复读作为隔离级别，采用B+树作为默认索引类型，并且提供行锁和外键约束。
MySQL运行的时候，InnoDB会在内存中建立缓冲池，用于缓冲数据和索引。由于锁的粒度小，写操作是不会锁定全表的,所以在并发度较高的场景下使用会提升效率的。
B+树 1.数据都存储在叶子节点，非叶子节点存放键值+指针。
2.叶子节点中包含所有的索引。
3.每个小节点都在大节点的范围中。
4.叶子节点都是使用双指针链接，提高访问性能，比如条件是&amp;gt;或者＜。 如果B+树高度为2的话，根节点指针数单个叶子节点记录行数 = 16kb/14 * 16 大约 1.8w+ 数据 如果B+树高度为3的话，那么这棵B+树的存放总记录数为：根节点指针数单个叶子节点记录行数 = 16kb/14 * 16kb/14 * 16 大约2kw+数据。
为什么使用B+树作为索引 一个是通过非叶子节点的结构，能够快速二分查找到数据，另一个是叶子节点通过双向链表连接，能够快速的进行区间范围查询。插入操作因为是通过主键自增的话，顺序插入很方便，并且删除时也只需要删除叶子节点就行。
MyISAM引擎 Memory引擎 分库分表 磁盘存储，单机MySQL当数据量较大时，当业务量较大时磁盘使用率大大降低 支撑微服务提高并发操作，在高并发的情况会有大量连接Mysql，分库分表可以让不同的服务访问对应的模块数据库，用于分担读写压力。 垂直拆分 分库：将原本的单库多表，拆分为多库单表，各个业务对应不同的数据库 分表：将表的常用字段和不常用字段进行分开建表，保留基本常用信息字段，还能增快查询。 水平拆分 分库：将user数据库分为user1和user2两个库，结构相同只是存储的数据集合不同 分表：按照hans取模或者时间范围对数据进行分表，例如user1（前1000名用户）、user2（1001~2000用户） 分库分表导致的问题 本地事务失效，需要使用分布式事务 需要使用分布式ID，用UUID或者雪花算法生成ID 跨库关联查询时，就需要分别查两次 查询排序，需要查到各个库数据再进行合并 分页查询同上 </description>
    </item>
    
    <item>
      <title>Kubernetes</title>
      <link>https://whyy1.github.io/post/kubernetes/</link>
      <pubDate>Thu, 10 Nov 2022 22:46:20 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/kubernetes/</guid>
      <description>最近把自己一个小玩意儿用docker部署到服务器后，开始尝试了解kubernetes，但是看了一眼阿里云k8s的收费情况，作为学生党当然是选择白嫖。现阶段只是了解学习的阶段，所以选择使用minikube来学习了解k8s。参考文档
Kubernetes 集群 Kubernetes 协调一个高可用计算机集群，每个计算机作为独立单元互相连接工作。 一个 Kubernetes 集群包含两种类型的资源:
Master 调度整个集群
Master节点负责管理整个集群，控制工作节点。 Nodes 负责运行应用
Node是一个虚拟机或者物理机，作为一个工作节点。它在 Kubernetes 集群中充当工作机器的角色，应该具有Kubelet：管理 Node 而且是 Node 与 Master 通信的代理以及用于处理容器操作的工具。
Master 管理集群，Node 用于托管正在运行的应用。 Deployment （部署） 创建 Kubernetes Deployment 配置，Deployment 指挥 Kubernetes 如何创建和更新应用程序的实例。通过修改Deployment文件来控制kubernetes来创建或是修改Pod。个人理解类似于dockerfile，表示应该如何创建Pods。
相关命令
# 查看 deployment kubectl get deployment # 创建命令，可以指定镜像版本 kubectl create deployment hello-node --image=registry.k8s.io/echoserver:1.4 # 也可以通过pod.yaml来部署Pod kubectl apply -f .\pod.yaml # 删除deployment kubectl delete deployment hello-minikube Pods kubernetes调度、管理的最小单位，一个Pod里面可以包含一个或多个容器，每个 Pod 有自己的虚拟IP。是运行一个应用程序的最小单元。
相关命令
# 查看Pods kubectl get pods # 通过命令行运行 kubectl run testapp --image=ccr.</description>
    </item>
    
    <item>
      <title>Hugo博客部署流程</title>
      <link>https://whyy1.github.io/post/hugo_add/</link>
      <pubDate>Tue, 08 Nov 2022 23:33:06 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/hugo_add/</guid>
      <description>Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。参考了文档以及一个UP主的视频，花了一个晚上的时间弄了一个人博客，最直观的感觉就是非常快速方便。博客地址
下面来做一下总结和流程回顾，首先需要安装Git和Hugo,可以参考视频和文档，都挺详细的。如何验证是否安装成功，运行以下命令出现版本号就说明安装成功了。
hugo version git version 安装好后就可以开始搭建自己的个人博客啦，此文主要记录一些常用操作。Hugo中文网站 、参考视频。
1.创建一个Hugo站点 进入你想要保存文件夹的路径，然后进入CMD，输入以下代码
hugo new site y1_blog #最后为文件夹名字 之后在路径下就会创建一个名为y1_blog的文件夹
2.选取一款皮肤主题 之后进入y1_blog文件夹，选取一款主题安装。皮肤主题网站Hugo上有挺多主题提供选择，我选择的主题是Paper，进入到y1_blog后，运行
git submodule add https://github.com/nanxiaobei/hugo-paper themes/paper 然后在y1_blog\themes下就会多了个paper文件夹，说明已经下载好了，然后在y1_blog目录下修改 config.toml文件的theme为paper
theme = &amp;#34;paper&amp;#34; 同时还可以设置其他一些信息
title = &amp;#39;歪衣的学习笔记&amp;#39; #博客标题名 github = &amp;#39;whyy1&amp;#39; #github用户名 avatar = &amp;#39;https://cdn.whyy1.top/avatar.svg&amp;#39; #设置头像照片链接，格式为svg name = &amp;#39;歪衣&amp;#39; #设置博客用户名字 bio = &amp;#39;学习是稳赚不赔的投资&amp;#39; #设置个性签名 3.启动Hugo服务器 设置好之后，在y1_blog根目录下运行以下命令，就能启动Hugo服务器了。
hugo server -D 如图最后所示，网址输入http://localhost:1313/ 就能访问了。 4.添加一篇文章 刚新建时因为没有文章，所以头像名字啥的有可能显示不出来，因此我们需要新建一篇文章，使用到的命令如下，在y1_blog\content\post\目录下就会新建一个essay.md文件，这是用Markdown格式写的一篇文章。Markdown教程
hugo new post/essay.md 添加好之后再次运行hugo server -D启动Hugo服务器，就可以看到刚才写的文章啦。
5.将博客部署到GitHub上 首先在GitHub上新建一个repository
新建好后复制repository的地址，例如https://whyy1.github.io/ ，然后之后进行一系列上传Git的操作，直接上代码块，有注释，也可以参考视频13:40~20:00的内容。
#在y1_blog/目录下CMD运行 #theme为主题，baseUrl为刚才新建的仓库地址 --buildDrafts为y1_blog/public/目录下生成静态文件 hugo --theme=paper --baseUrl=&amp;#34;https://whyy1.</description>
    </item>
    
    <item>
      <title>docker常用命令</title>
      <link>https://whyy1.github.io/post/essay/</link>
      <pubDate>Tue, 01 Nov 2022 22:48:44 +0800</pubDate>
      
      <guid>https://whyy1.github.io/post/essay/</guid>
      <description>Docker镜像创建 创建dockerflie文件 # 最低版本go的依赖 FROM golang:1.17.7 # 配置模块代理 ENV GOPROXY=https://goproxy.cn,direct # 复制文件目录下的所有代码 ADD . /whygo #默认进入文件目录 WORKDIR /whygo # 复制代码 ADD /whygo/go.mod . ADD /whygo/go.sum . # 下载依赖 RUN go mod download # 运行命令，安装依赖 # 例如 RUN npm install &amp;amp;&amp;amp; cd /app &amp;amp;&amp;amp; mkdir logs # ADD ./whygo . ENV CGO_ENABLED=0 ENV GOOS=linux ENV GOARCH=amd64 # RUN 命令可以有多个，但是可以用 &amp;amp;&amp;amp; 连接多个命令来减少层级。 # 构建exe文件，名字为demo RUN go build -tags netgo -o demo # CMD 指令只能一个，是容器启动后执行的命令，算是程序的入口。 # 默认运行 demo ENTRYPOINT [ &amp;#34;.</description>
    </item>
    
  </channel>
</rss>
